#!/usr/bin/python3

import os
import sys
import socket
import errno
import signal
import multiprocessing
import subprocess
import json
import time
import argparse
from datetime import datetime
import logging
from abc import ABC,abstractmethod 


DIRPATH = os.path.dirname(os.path.realpath(__file__))
# DIRPATH = '/'
POCKETD_SOCKET_PATH = f'{DIRPATH}/tmp/pocketd.sock'
POCKETD_SOCKET: socket.socket
CONCURRENT_CONNECTIONS = 1
MULTIPROC = True

class GlobalOptions:
    ratio = None
    
    @staticmethod
    def init_configs(parsed_args):
        GlobalOptions.ratio = parsed_args.ratio

        logging.info(f'self.ratio={GlobalOptions.ratio}')

class DockerUtils:
    @staticmethod
    def get_container_id(name: str):
        container_id = subprocess.check_output(f'docker inspect --format=\'{{{{.Id}}}}\' {name}', shell=True, encoding='utf-8').replace('/','').strip()
        return container_id

    @staticmethod
    def get_original_resource_limits(id: str):
        memory_limit = subprocess.check_output(f'docker inspect --format=\'{{{{ .HostConfig.Memory }}}}\' {id}')
        cpu_limit = float(subprocess.check_output(f'docker inspect --format=\'{{{{ .HostConfig.NanoCpus }}}}\' {id}'))/1000/1000000 # make nano to micro, micro to core.
        return memory_limit, cpu_limit

    @staticmethod
    def get_memory_limit(id: str):
        with open(f'/sys/fs/cgroup/memory/docker/{id}/memory.limit_in_bytes', 'r') as limit_in_bytes:
            memory_limit = limit_in_bytes.read()
        return memory_limit

    @staticmethod
    def get_cpus_limit(id: str):
        with open(f'/sys/fs/cgroup/cpu/docker/{id}/cpu.cfs_period_us', 'r') as cfs_period_us:
            cpu_denominator = float(cfs_period_us.read())
        with open(f'/sys/fs/cgroup/cpu/docker/{id}/cpu.cfs_quota_us', 'r') as cfs_quota_us:
            cpu_numerator = float(cfs_quota_us.read())
        return cpu_numerator/cpu_denominator

    @staticmethod
    def set_memory_limit(id: str, amount: str):
        with open(f'/sys/fs/cgroup/memory/docker/{id}/memory.limit_in_bytes', 'w') as limit_in_bytes:
            limit_in_bytes.write(amount)

    @staticmethod
    def set_cpus_limit(id: str, amount: float, denominator = 100000):
        numerator = str(int(amount * denominator))
        logging.debug(f'amount={amount}, numerator={numerator}')
        with open(f'/sys/fs/cgroup/cpu/docker/{id}/cpu.cfs_period_us', 'w') as cfs_period_us:
            cfs_period_us.write(str(denominator))
        with open(f'/sys/fs/cgroup/cpu/docker/{id}/cpu.cfs_quota_us', 'w') as cfs_quota_us:
            cfs_quota_us.write(str(numerator))

    @staticmethod
    def migrate_memory(ratio: float, source_id: str, dest_id: str):
        server_old_memory_limit = float(DockerUtils.get_memory_limit(dest_id))
        client_old_memory_limit = float(DockerUtils.get_memory_limit(source_id))

        source_amount = str(int(client_old_memory_limit * (1 - ratio)))
        dest_amount = str(int(server_old_memory_limit + ratio * client_old_memory_limit))

        DockerUtils.set_memory_limit(source_id, source_amount)
        DockerUtils.set_memory_limit(dest_id, dest_amount)
        
    @staticmethod
    def migrate_cpu(ratio: float, source_id: str, dest_id: str):
        server_old_cpu_limit = float(DockerUtils.get_cpus_limit(dest_id))
        client_old_cpu_limit = float(DockerUtils.get_cpus_limit(source_id))

        source_amount = float(client_old_cpu_limit * (1 - ratio))
        dest_amount = float(server_old_cpu_limit + ratio * client_old_cpu_limit)

        DockerUtils.set_cpus_limit(source_id, source_amount)
        DockerUtils.set_cpus_limit(dest_id, dest_amount)
        
    @staticmethod
    def migrate_resource(ratio: float, source_id: str, dest_id: str):
        DockerUtils.migrate_memory(ratio, source_id, dest_id)
        DockerUtils.migrate_cpu(ratio, source_id, dest_id)
        
    @staticmethod
    def recover_resource(id: str):
        memory, cpus = DockerUtils.get_original_resource_limits(id)
        DockerUtils.set_memory_limit(id, memory)
        DockerUtils.set_cpus_limit(id, cpus)

class Sender(ABC):
    @abstractmethod
    def handle(self, command: str):
        pass

    def __init__(self, args_dict):
        self.__dict__ = args_dict

class BackEnd(Sender):
    pass

class CLI(Sender):
    def __init__(self, args_dict):
        super().__init__(args_dict)

    def handle(self, command: str):
        if command == 'run' or command == 'start':
            self.run()
        else:
            raise Exception(f'Invalid command {command}')

    
    def run(self):
        client_name = self.client
        server_name = self.service
        
        client_euid = DockerUtils.get_container_id(client_name)
        server_euid = DockerUtils.get_container_id(server_name)

        logging.debug(f'client-euid={client_euid}, server-euid={server_euid}')

        DockerUtils.migrate_resource(GlobalOptions.ratio, client_euid, server_euid)


class FrontEnd(Sender):
    pass

def sender_factory(sent_by: str, args_dict: dict):
    if sent_by == 'BE':
        sender = BackEnd(args_dict)
    elif sent_by == 'CLI':
        sender = CLI(args_dict)
    elif sent_by == 'FE':
        sender = FrontEnd(args_dict)
    else:
        raise Exception(f'No such sender = {sent_by}')
    return sender

def remove_remaining_sockets():
    if os.path.exists(POCKETD_SOCKET_PATH):
        os.unlink(POCKETD_SOCKET_PATH)

def create_and_bind_sockets():
    global POCKETD_SOCKET

    POCKETD_SOCKET = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
    POCKETD_SOCKET.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    POCKETD_SOCKET.bind(POCKETD_SOCKET_PATH)
    os.chmod(POCKETD_SOCKET_PATH, 0o660)
    os.chown(POCKETD_SOCKET_PATH, 1000, 1011) # 1000, 1011: cc uid, cc gid

def is_target_done(pid: int):
    try:
        os.kill(pid, 0)
    except OSError as err:
        if err.errno == errno.ESRCH: # process does not exist, errno==3
            return True
    return False

def wait_until_process_terminates(pid: int):
    time.sleep(0.1)
    while True:
        if is_target_done(pid):
            break

def run_server():
    POCKETD_SOCKET.listen(CONCURRENT_CONNECTIONS)
    while True:
        logging.info('[POCKETD] waiting for requests...')
        
        conn, _addr = POCKETD_SOCKET.accept()
        # https://stackoverflow.com/questions/9644251/how-do-unix-domain-sockets-differentiate-between-multiple-clients

        if MULTIPROC: 
            process = multiprocessing.Process(target=handle_client, args=(conn, _addr))
            process.daemon = True
            process.start()
        else:
            handle_client(conn, _addr)


def do_something(sent_by: str, command: str, args_dict: dict):
    sender = sender_factory(sent_by, args_dict)
    sender.handle(command)

    return

    timestamp = str(datetime.now()).replace(' ', '-')
    p = subprocess.Popen(f'exec perf stat -e {",".join(events)} -p {pid} -o ./data/perf_stat_{container_name}_{timestamp}.log', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    wait_until_process_terminates(pid)

    try:
        stdout, stderr = p.communicate(timeout=1)
    except:
        p.send_signal(signal.SIGINT)
        stdout, stderr = p.communicate(timeout=1)
    
    with open(f'./data/perf_stat_{container_name}_{timestamp}.log') as f:
        while True:
            line = f.readline().rstrip('\n')
            logging.info(line)
            if line == '':
                break

def parse_arguments(string: str):
    args_dict = json.loads(string)
    logging.info(args_dict)
    sender = args_dict.pop('sender')
    command = args_dict.pop('command')

    return sender, command, args_dict
    
    # if args_dict['type'] == 'open-proc-ns':
    #     pass
    # elif args_dict['type'] == 'closed-proc-ns':
    #     container_id = args_dict['cid']
    #     args_dict['pid'] = subprocess.check_output(f'docker inspect --format=\'{{{{.State.Pid}}}}\' {container_id}', shell=True, encoding='utf-8').strip()
    #     args_dict['container_name'] = subprocess.check_output(f'docker inspect --format=\'{{{{.Name}}}}\' {container_id}', shell=True, encoding='utf-8').replace('/','').strip()
    # return int(args_dict['pid']), args_dict['events'], args_dict['container_name'] 


def handle_client(conn, addr):
    logging.info('handle client!')
    while True:
        data_received = conn.recv(1024)
        logging.debug(f'data_received={data_received}')
        sender, command, args_dict = parse_arguments(data_received.decode('utf-8'))
        logging.debug(f'sender={sender}, command={command}, args_dict={args_dict}')
        do_something(sender, command, args_dict)
        data_to_send = 'done'.encode('utf-8')
        conn.send(data_to_send)
        break
    conn.close()

def finalize(signum, frame):
    logging.info('finalizing workers...')
    for process in multiprocessing.active_children():
        # logging.info("Shutting down process %r", process)
        process.terminate()
        process.join()
    sys.exit()

if __name__ == '__main__':
    if os.geteuid() != 0:
        exit('''
        You need to have root privileges to run this script.
        Please try again, this time using 'sudo'. Exiting.''')

    signal.signal(signal.SIGINT, finalize)
    logging.basicConfig(level=logging.DEBUG, \
                        format='[%(asctime)s, %(lineno)d|POCKETD] %(message)s')

    parser = argparse.ArgumentParser(prog='pocketd',
            usage='%(prog)s [options]',
            description='''
            Pocket Daemon.''')

    parser.add_argument('-r', '--ratio', type=float, default=0.5, help='ratio to migrate to the service')
    GlobalOptions.init_configs(parser.parse_args())

    remove_remaining_sockets()
    create_and_bind_sockets()
    run_server()